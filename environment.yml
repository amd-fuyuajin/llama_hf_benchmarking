name: llama_benchmark_env
channels:
  - conda-forge
dependencies:
  - _libgcc_mutex=0.1=conda_forge
  - _openmp_mutex=4.5=2_gnu
  - bzip2=1.0.8=h4bc722e_7
  - ca-certificates=2025.1.31=hbcca054_0
  - gperftools=2.10=h09c0d1c_0
  - ld_impl_linux-64=2.43=h712a8e2_4
  - libexpat=2.7.0=h5888daf_0
  - libffi=3.4.6=h2dba641_1
  - libgcc=14.2.0=h767d61c_2
  - libgcc-ng=14.2.0=h69a702a_2
  - libgomp=14.2.0=h767d61c_2
  - liblzma=5.8.1=hb9d3cd8_0
  - libnsl=2.0.1=hd590300_0
  - libsqlite=3.49.1=hee588c1_2
  - libstdcxx=14.2.0=h8f9b012_2
  - libstdcxx-ng=14.2.0=h4852527_2
  - libunwind=1.6.2=h9c3ff4c_0
  - libuuid=2.38.1=h0b41bf4_0
  - libxcrypt=4.4.36=hd590300_1
  - libzlib=1.3.1=hb9d3cd8_2
  - ncurses=6.5=h2d0b736_3
  - openssl=3.5.0=h7b32b05_0
  - perl=5.32.1=7_hd590300_perl5
  - pip=25.0.1=pyh8b19718_0
  - python=3.12.10=h9e4cc4f_0_cpython
  - readline=8.2=h8c095d6_2
  - setuptools=78.1.0=pyhff2d567_0
  - tk=8.6.13=noxft_h4845f30_101
  - wheel=0.45.1=pyhd8ed1ab_1
  - pip:
      - --extra-index-url https://download.pytorch.org/whl/cpu
      - certifi==2025.1.31
      - charset-normalizer==3.4.1
      - deprecated==1.2.18
      - filelock==3.13.1
      - fsspec==2024.6.1
      - huggingface-hub==0.30.2
      - idna==3.10
      - intel-extension-for-pytorch==2.6.0
      - jinja2==3.1.4
      - markupsafe==2.1.5
      - mpmath==1.3.0
      - networkx==3.3
      - numpy==2.1.2
      - oneccl-bind-pt==2.6.0+cpu
      - packaging==25.0
      - pandas==2.2.3
      - pillow==11.0.0
      - psutil==7.0.0
      - python-dateutil==2.9.0.post0
      - pytz==2025.2
      - pyyaml==6.0.2
      - regex==2024.11.6
      - requests==2.32.3
      - safetensors==0.5.3
      - six==1.17.0
      - sympy==1.13.1
      - tokenizers==0.20.3
      - torch==2.6.0+cpu
      - torchaudio==2.6.0+cpu
      - torchvision==0.21.0+cpu
      - tqdm==4.67.1
      - transformers==4.46.2
      - typing-extensions==4.12.2
      - tzdata==2025.2
      - urllib3==2.4.0
      - wrapt==1.17.2
      - zentorch==5.0.2
